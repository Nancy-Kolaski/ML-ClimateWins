{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd80b91d-f557-4e1c-8cca-91c1551dd4dc",
   "metadata": {},
   "source": [
    "# Task 2.4 - CNN (Convulusion Neural Network)- CLimate Wins¶ - Evaluating Hyperparameters, Part 2 -NK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952f4a3-dda0-4e19-b841-b581aafc279c",
   "metadata": {},
   "source": [
    "## This script contains the following:\n",
    "#### 1. Import Libraries and Data\n",
    "- tensorflow and keras\n",
    "- Data: unscaled weather observations, pleasant weather predictions\n",
    "#### 2. Reshaping for modeling\n",
    "#### 3. Data Split\n",
    "#### 4. Hyperparameter Tuning with **Bayesian Optimization**\n",
    "#### 5. Building the CNN Model with Optimized Hyperparameters\n",
    "* Determine the number of time steps for the input data\n",
    "* Determine the dimensionality of the input data\n",
    "* Specify the number of classes for the target variable\n",
    "* n_classes = 15\n",
    "* Create a scorer for accuracy\n",
    "* score_acc = make_scorer(accuracy_score)using with Bayesian Optimization\n",
    "#### 5.Buid the CNN Model with these Optimized Hyperparameters\n",
    "#### 6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c3474-168f-4f41-a051-402c8ece08f9",
   "metadata": {},
   "source": [
    "## 1. Import libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf92d95-5c49-4107-8a0e-af400995264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier  # Use scikeras for scikit-learn compatibility\n",
    "from math import floor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow.keras.layers import LeakyReLU  # Use tensorflow.keras instead of keras\n",
    "LeakyReLU = LeakyReLU(negative_slope=0.1)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07f9a71-79c8-4c42-b95a-eda10ab3c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to ensure charts are displayed inline in the notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb6e05f-5d59-4c4f-b104-9d1c530e5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import path\n",
    "path = r'/Users/nancykray/Desktop/CF/Machine Learning /ClimateWins/Data Sets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1d8578-dca0-43b4-9ead-042e1a6c41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clean X dataset\n",
    "X = pd.read_csv(os.path.join(path, 'Prepared Data', 'unscaled_cleaned.csv'), index_col = 0)\n",
    "\n",
    "# import clean Y dataset\n",
    "y = pd.read_csv(os.path.join(path, 'Prepared Data', 'answers_cleaned.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b44415-c56a-4c57-a402-01e2289d9667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>...</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>MUNCHENB_pressue</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0320</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  BASEL_global_radiation  \\\n",
       "0                  7            0.85           1.018                    0.32   \n",
       "1                  6            0.84           1.018                    0.36   \n",
       "2                  8            0.90           1.018                    0.18   \n",
       "3                  3            0.92           1.018                    0.58   \n",
       "4                  6            0.95           1.018                    0.65   \n",
       "\n",
       "   BASEL_precipitation  BASEL_sunshine  BASEL_temp_mean  BASEL_temp_min  \\\n",
       "0                 0.09             0.7              6.5             0.8   \n",
       "1                 1.05             1.1              6.1             3.3   \n",
       "2                 0.30             0.0              8.5             5.1   \n",
       "3                 0.00             4.1              6.3             3.8   \n",
       "4                 0.14             5.4              3.0            -0.7   \n",
       "\n",
       "   BASEL_temp_max  BELGRADE_cloud_cover  ...  VALENTIA_pressure  \\\n",
       "0            10.9                     1  ...             1.0003   \n",
       "1            10.1                     6  ...             1.0007   \n",
       "2             9.9                     6  ...             1.0096   \n",
       "3            10.6                     8  ...             1.0184   \n",
       "4             6.0                     8  ...             1.0328   \n",
       "\n",
       "   VALENTIA_global_radiation  VALENTIA_precipitation  VALENTIA_sunshine  \\\n",
       "0                       0.45                    0.34                4.7   \n",
       "1                       0.25                    0.84                0.7   \n",
       "2                       0.17                    0.08                0.1   \n",
       "3                       0.13                    0.98                0.0   \n",
       "4                       0.46                    0.00                5.7   \n",
       "\n",
       "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \\\n",
       "0                 8.5                6.0               10.9   \n",
       "1                 8.9                5.6               12.1   \n",
       "2                10.5                8.1               12.9   \n",
       "3                 7.4                7.3               10.6   \n",
       "4                 5.7                3.0                8.4   \n",
       "\n",
       "   KASSEL_cloud_cover  MUNCHENB_pressue  STOCKHOLM_humidity  \n",
       "0                   8            1.0304                0.98  \n",
       "1                   6            1.0292                0.62  \n",
       "2                   8            1.0320                0.69  \n",
       "3                   6            1.0443                0.98  \n",
       "4                   7            1.0430                0.96  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf2e190-cdb4-4e20-952b-59b488e3f7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0                       0                          0   \n",
       "1                       0                          0   \n",
       "2                       0                          0   \n",
       "3                       0                          0   \n",
       "4                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698fc84-bc75-477b-b8de-0884683d7522",
   "metadata": {},
   "source": [
    "## 2. Reshaping for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c890859d-01d7-4648-8d11-40fb1f18410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306ae1d0-0904-4fb2-83e3-0f1b2292eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-shape 3-D object using the below code, where -1 means \"the shape that fits with the rest\"\n",
    "\n",
    "X = X.reshape(-1,15,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ee76bc-5903-4068-8e7a-4399726aeb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c99f9e-47f7-4426-b3cb-b7842d86d8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of y\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49a0643-6173-4728-9ed3-1267f82c45ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape after argmax: (22950,)\n"
     ]
    }
   ],
   "source": [
    "# re-shape y to (22950, )\n",
    "y = np.argmax(y, axis=1)\n",
    "print(\"y shape after argmax:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2868c9-8b33-4685-a767-1de3ec019374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in y to ensure it's correct\n",
    "print(\"Unique values in y:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fd385-e51e-426f-81ad-5098597a78b5",
   "metadata": {},
   "source": [
    "## 3. Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468bc092-ce1c-4d56-80a9-560d04beb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d5445c-644e-497e-83d0-ff4ebd77ed23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e097cbf-7973-495a-a78f-930de9e4e5d8",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning with Bayesian Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bbd3488-6c79-473e-b0de-61738c6f35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of time steps for the input data\n",
    "timesteps = X_train.shape[1]\n",
    "\n",
    "# Determine the dimensionality of the input data\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "# Specify the number of classes for the target variable\n",
    "n_classes = 15  \n",
    "\n",
    "# Create a scorer for accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f79978cb-7060-4b30-b4f4-e04b49bb240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'SGD']\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer_name = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "\n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, input_dim)))\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel, activation=activation))\n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=127))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax'))  # sigmoid softmax\n",
    "        \n",
    "        # Create a new optimizer instance for each iteration\n",
    "        if optimizer_name == 'Adam':\n",
    "            optimizer_instance = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'SGD':\n",
    "            optimizer_instance = SGD(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'RMSprop':\n",
    "            optimizer_instance = RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adadelta':\n",
    "            optimizer_instance = Adadelta(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adagrad':\n",
    "            optimizer_instance = Adagrad(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adamax':\n",
    "            optimizer_instance = Adamax(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Nadam':\n",
    "            optimizer_instance = Nadam(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Ftrl':\n",
    "            optimizer_instance = Ftrl(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer_instance, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=20)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=127)\n",
    "    results = []\n",
    "    for train, test in kfold.split(X, y):\n",
    "        model = cnn_model()\n",
    "        model.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=0, callbacks=[es])\n",
    "        scores = model.evaluate(X[test], y[test], verbose=1)\n",
    "        results.append(scores[1])  # Assuming accuracy is the second metric\n",
    "    return np.mean(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "850be897-2e8a-4c53-a8ff-10d19624a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.6451 - loss: 48.3471\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.1860 - loss: 93.3577\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.0360 - loss: 79.9948\n",
      "Epoch 29: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.1894 - loss: 42.0225\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.6544 - loss: 75.5161\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.3419   \u001b[39m | \u001b[39m4.714    \u001b[39m | \u001b[39m232.0    \u001b[39m | \u001b[39m0.186    \u001b[39m | \u001b[39m0.4546   \u001b[39m | \u001b[39m64.17    \u001b[39m | \u001b[39m1.173    \u001b[39m | \u001b[39m1.883    \u001b[39m | \u001b[39m2.431    \u001b[39m | \u001b[39m0.6709   \u001b[39m | \u001b[39m52.56    \u001b[39m | \u001b[39m0.9062   \u001b[39m | \u001b[39m0.7344   \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.6451 - loss: nan\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.6552 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6520 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6617 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6544 - loss: nan\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.6434   \u001b[39m | \u001b[35m1.573    \u001b[39m | \u001b[35m271.1    \u001b[39m | \u001b[35m0.6497   \u001b[39m | \u001b[35m0.3143   \u001b[39m | \u001b[35m56.8     \u001b[39m | \u001b[35m2.813    \u001b[39m | \u001b[35m1.188    \u001b[39m | \u001b[35m2.266    \u001b[39m | \u001b[35m0.2669   \u001b[39m | \u001b[35m92.48    \u001b[39m | \u001b[35m0.1275   \u001b[39m | \u001b[35m0.4802   \u001b[39m |\n",
      "Epoch 25: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0341 - loss: 24.6371   \n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6552 - loss: 3.5759\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0738 - loss: 37.1079\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.6617 - loss: 50.5116\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 22.5429\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.408    \u001b[39m | \u001b[39m6.052    \u001b[39m | \u001b[39m361.9    \u001b[39m | \u001b[39m0.4819   \u001b[39m | \u001b[39m0.3475   \u001b[39m | \u001b[39m83.42    \u001b[39m | \u001b[39m1.691    \u001b[39m | \u001b[39m2.908    \u001b[39m | \u001b[39m2.201    \u001b[39m | \u001b[39m0.3927   \u001b[39m | \u001b[39m67.47    \u001b[39m | \u001b[39m0.8815   \u001b[39m | \u001b[39m1.416    \u001b[39m |\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.6451 - loss: 1.2029\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.6552 - loss: 1.2607\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.6520 - loss: 1.2109\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.6617 - loss: 1.1379\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.6544 - loss: 1.2317\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m5.379    \u001b[39m | \u001b[39m539.7    \u001b[39m | \u001b[39m0.201    \u001b[39m | \u001b[39m0.3324   \u001b[39m | \u001b[39m58.97    \u001b[39m | \u001b[39m1.07     \u001b[39m | \u001b[39m1.821    \u001b[39m | \u001b[39m2.718    \u001b[39m | \u001b[39m0.3971   \u001b[39m | \u001b[39m31.79    \u001b[39m | \u001b[39m0.9366   \u001b[39m | \u001b[39m5.283    \u001b[39m |\n",
      "Epoch 23: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6451 - loss: 1.1476\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.6552 - loss: 1.1867\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6520 - loss: 1.1529\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.6617 - loss: 1.1370\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6544 - loss: 1.1479\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m8.951    \u001b[39m | \u001b[39m292.0    \u001b[39m | \u001b[39m0.1595   \u001b[39m | \u001b[39m0.4401   \u001b[39m | \u001b[39m61.92    \u001b[39m | \u001b[39m1.349    \u001b[39m | \u001b[39m1.874    \u001b[39m | \u001b[39m2.395    \u001b[39m | \u001b[39m0.5142   \u001b[39m | \u001b[39m74.0     \u001b[39m | \u001b[39m0.2923   \u001b[39m | \u001b[39m2.465    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.6240 - loss: 1.0720\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6560 - loss: 1.1803\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.6796 - loss: 0.9426\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7571 - loss: 0.7433\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.5903 - loss: 1.0100\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.6522   \u001b[39m | \u001b[35m2.783    \u001b[39m | \u001b[35m778.9    \u001b[39m | \u001b[35m0.1646   \u001b[39m | \u001b[35m0.3458   \u001b[39m | \u001b[35m31.58    \u001b[39m | \u001b[35m1.392    \u001b[39m | \u001b[35m2.01     \u001b[39m | \u001b[35m1.545    \u001b[39m | \u001b[35m0.2438   \u001b[39m | \u001b[35m41.07    \u001b[39m | \u001b[35m0.9895   \u001b[39m | \u001b[35m4.893    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.8007 - loss: 0.5494\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7620 - loss: 0.7051\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7348 - loss: 0.7425\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7437 - loss: 0.7439\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7703 - loss: 0.6751\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.7561   \u001b[39m | \u001b[35m4.522    \u001b[39m | \u001b[35m744.1    \u001b[39m | \u001b[35m0.9174   \u001b[39m | \u001b[35m0.4632   \u001b[39m | \u001b[35m96.58    \u001b[39m | \u001b[35m2.627    \u001b[39m | \u001b[35m1.598    \u001b[39m | \u001b[35m1.644    \u001b[39m | \u001b[35m0.677    \u001b[39m | \u001b[35m14.0     \u001b[39m | \u001b[35m0.7135   \u001b[39m | \u001b[35m3.301    \u001b[39m |\n",
      "Epoch 29: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 328.3553\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0030 - loss: 696.9302\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1888 - loss: 146.1719\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0625 - loss: 209.5109\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 209.5018\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.3114   \u001b[39m | \u001b[39m5.759    \u001b[39m | \u001b[39m605.0    \u001b[39m | \u001b[39m0.1657   \u001b[39m | \u001b[39m0.3829   \u001b[39m | \u001b[39m90.37    \u001b[39m | \u001b[39m2.722    \u001b[39m | \u001b[39m1.829    \u001b[39m | \u001b[39m2.336    \u001b[39m | \u001b[39m0.757    \u001b[39m | \u001b[39m82.59    \u001b[39m | \u001b[39m0.674    \u001b[39m | \u001b[39m2.146    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.1383\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 1.1220\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: nan\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m1.71     \u001b[39m | \u001b[39m383.0    \u001b[39m | \u001b[39m0.1859   \u001b[39m | \u001b[39m0.3541   \u001b[39m | \u001b[39m79.76    \u001b[39m | \u001b[39m1.194    \u001b[39m | \u001b[39m1.526    \u001b[39m | \u001b[39m2.075    \u001b[39m | \u001b[39m0.9041   \u001b[39m | \u001b[39m84.38    \u001b[39m | \u001b[39m0.8003   \u001b[39m | \u001b[39m0.09905  \u001b[39m |\n",
      "Epoch 29: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6451 - loss: 1.3841\n",
      "Epoch 29: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.6552 - loss: 1.3969\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.1888 - loss: 1.4050\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.6617 - loss: 1.2542\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.6544 - loss: 1.1849\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.5534   \u001b[39m | \u001b[39m8.678    \u001b[39m | \u001b[39m869.4    \u001b[39m | \u001b[39m0.6053   \u001b[39m | \u001b[39m0.3531   \u001b[39m | \u001b[39m71.57    \u001b[39m | \u001b[39m2.462    \u001b[39m | \u001b[39m1.09     \u001b[39m | \u001b[39m2.968    \u001b[39m | \u001b[39m0.9803   \u001b[39m | \u001b[39m46.71    \u001b[39m | \u001b[39m0.6235   \u001b[39m | \u001b[39m2.347    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6451 - loss: 1.2399\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.6552 - loss: 1.1421\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6520 - loss: 1.1471\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.6617 - loss: 1.1268\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.6544 - loss: 1.1465\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m1.267    \u001b[39m | \u001b[39m961.5    \u001b[39m | \u001b[39m0.8919   \u001b[39m | \u001b[39m0.4301   \u001b[39m | \u001b[39m81.52    \u001b[39m | \u001b[39m2.994    \u001b[39m | \u001b[39m2.373    \u001b[39m | \u001b[39m1.792    \u001b[39m | \u001b[39m0.05079  \u001b[39m | \u001b[39m45.2     \u001b[39m | \u001b[39m0.7669   \u001b[39m | \u001b[39m6.906    \u001b[39m |\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.5542 - loss: 1031910.1250\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.5493 - loss: 29255.9883\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.5350 - loss: 115167.2188\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.6307 - loss: 23194.9785\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.6648 - loss: 2080220.1250\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.5769   \u001b[39m | \u001b[39m7.83     \u001b[39m | \u001b[39m284.2    \u001b[39m | \u001b[39m0.2654   \u001b[39m | \u001b[39m0.4736   \u001b[39m | \u001b[39m97.1     \u001b[39m | \u001b[39m1.922    \u001b[39m | \u001b[39m1.464    \u001b[39m | \u001b[39m2.467    \u001b[39m | \u001b[39m0.9535   \u001b[39m | \u001b[39m44.37    \u001b[39m | \u001b[39m0.1684   \u001b[39m | \u001b[39m1.164    \u001b[39m |\n",
      "Epoch 28: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.6451 - loss: 1.6838\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.6552 - loss: 10.4498\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.6520 - loss: 20.1715\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.1894 - loss: 19.8540\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.6544 - loss: 3.0460\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.5534   \u001b[39m | \u001b[39m5.513    \u001b[39m | \u001b[39m996.0    \u001b[39m | \u001b[39m0.9747   \u001b[39m | \u001b[39m0.3528   \u001b[39m | \u001b[39m96.45    \u001b[39m | \u001b[39m1.56     \u001b[39m | \u001b[39m1.62     \u001b[39m | \u001b[39m2.64     \u001b[39m | \u001b[39m0.9727   \u001b[39m | \u001b[39m19.0     \u001b[39m | \u001b[39m0.7042   \u001b[39m | \u001b[39m5.893    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.1447\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 1.1511\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 1.1400\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 1.1273\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.1299\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m2.229    \u001b[39m | \u001b[39m222.4    \u001b[39m | \u001b[39m0.215    \u001b[39m | \u001b[39m0.4863   \u001b[39m | \u001b[39m95.6     \u001b[39m | \u001b[39m2.074    \u001b[39m | \u001b[39m1.007    \u001b[39m | \u001b[39m2.594    \u001b[39m | \u001b[39m0.2169   \u001b[39m | \u001b[39m85.73    \u001b[39m | \u001b[39m0.3766   \u001b[39m | \u001b[39m1.242    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7962 - loss: 0.5677\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7882 - loss: 0.6027\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.6301\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.6584\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.5919\n",
      "| \u001b[35m15       \u001b[39m | \u001b[35m0.7786   \u001b[39m | \u001b[35m3.8      \u001b[39m | \u001b[35m283.3    \u001b[39m | \u001b[35m0.7075   \u001b[39m | \u001b[35m0.4555   \u001b[39m | \u001b[35m34.66    \u001b[39m | \u001b[35m1.933    \u001b[39m | \u001b[35m2.556    \u001b[39m | \u001b[35m2.461    \u001b[39m | \u001b[35m0.05664  \u001b[39m | \u001b[35m78.55    \u001b[39m | \u001b[35m0.4846   \u001b[39m | \u001b[35m0.4789   \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7994 - loss: 0.5779\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7231 - loss: 0.7964\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7393 - loss: 0.7425\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7475 - loss: 0.7503\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7712 - loss: 0.7126\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7495   \u001b[39m | \u001b[39m5.049    \u001b[39m | \u001b[39m743.8    \u001b[39m | \u001b[39m0.945    \u001b[39m | \u001b[39m0.4867   \u001b[39m | \u001b[39m96.16    \u001b[39m | \u001b[39m2.99     \u001b[39m | \u001b[39m1.654    \u001b[39m | \u001b[39m1.44     \u001b[39m | \u001b[39m0.6044   \u001b[39m | \u001b[39m13.87    \u001b[39m | \u001b[39m0.8185   \u001b[39m | \u001b[39m2.614    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6579 - loss: 1.0967\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 1.1454\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7508 - loss: 0.8070\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 1.1342\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3030 - loss: 3.4863\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.5976   \u001b[39m | \u001b[39m6.3      \u001b[39m | \u001b[39m296.4    \u001b[39m | \u001b[39m0.5816   \u001b[39m | \u001b[39m0.3741   \u001b[39m | \u001b[39m28.98    \u001b[39m | \u001b[39m2.824    \u001b[39m | \u001b[39m2.794    \u001b[39m | \u001b[39m2.408    \u001b[39m | \u001b[39m0.1504   \u001b[39m | \u001b[39m92.93    \u001b[39m | \u001b[39m0.7251   \u001b[39m | \u001b[39m0.3468   \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8310 - loss: 0.5120\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8097 - loss: 0.5813\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8098 - loss: 0.5441\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7801 - loss: 0.6426\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8067 - loss: 0.5738\n",
      "| \u001b[35m18       \u001b[39m | \u001b[35m0.8004   \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m281.5    \u001b[39m | \u001b[35m0.9758   \u001b[39m | \u001b[35m0.4122   \u001b[39m | \u001b[35m34.41    \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m2.475    \u001b[39m | \u001b[35m0.001    \u001b[39m | \u001b[35m62.18    \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.213    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6451 - loss: 2.3130\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.6552 - loss: 2.1610\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.6520 - loss: 2.0030\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.6617 - loss: 2.0607\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.6544 - loss: 2.1598\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m269.4    \u001b[39m | \u001b[39m0.1014   \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.001    \u001b[39m | \u001b[39m70.5     \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m7.0      \u001b[39m |\n",
      "=========================================================================================================================================================================\n",
      "Search took 23.673212083180747 minutes\n"
     ]
    }
   ],
   "source": [
    "# Start timing the Bayesian Optimization process\n",
    "start = time.time()\n",
    "\n",
    "# Define the hyperparameter space for Bayesian Optimization\n",
    "params = {\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation': (0, 9),  # 9\n",
    "    'optimizer': (0, 7),  # 7\n",
    "    'learning_rate': (0.001, 1),\n",
    "    'batch_size': (200, 1000), #(10, 50), #\n",
    "    'epochs': (20, 100),\n",
    "    'layers1': (1, 3),\n",
    "    'layers2': (1, 3),\n",
    "    'normalization': (0, 1),\n",
    "    'dropout': (0, 1),\n",
    "    'dropout_rate': (0.3, 0.5)\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=127)\n",
    "nn_opt.maximize(init_points=15, n_iter=4)  # 25\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92c0ea99-9bd9-4a00-8384-deaa038527b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 0.0, 'batch_size': 281.48169235622623, 'dropout': 0.9757800412872902, 'dropout_rate': 0.4122128142503167, 'epochs': 34.406311326655896, 'kernel': 1.0, 'layers1': 1.0, 'layers2': 2.4750299150898654, 'learning_rate': 0.001, 'neurons': 62.18483076408598, 'normalization': 0.0, 'optimizer': 1.2127742292079406}\n",
      "Highest Accuracy: 0.800435733795166\n"
     ]
    }
   ],
   "source": [
    "best_params = nn_opt.max['params']\n",
    "best_score = nn_opt.max['target']\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Highest Accuracy: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ceb97f5-c687-4a6b-b6d7-59ddea902a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "Activation: relu\n",
      "Batch Size: 281\n",
      "Dropout Rate: 0.4122\n",
      "Epochs: 34\n",
      "Kernel Size: 1\n",
      "Layers1: 1\n",
      "Layers2: 2\n",
      "Learning Rate: 0.0010\n",
      "Neurons: 62\n",
      "Normalization: 0.0000\n",
      "Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best parameters from the optimization result\n",
    "optimum = nn_opt.max['params']\n",
    "\n",
    "# Assign the best parameters to their respective variables\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'LeakyReLU', 'relu']\n",
    "activation = activationL[round(optimum['activation'])]\n",
    "\n",
    "# Convert the hyperparameters to their integer form where necessary\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimum['kernel'] = round(optimum['kernel'])\n",
    "\n",
    "optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "optimizerD = {\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "\n",
    "# Retrieve the optimizer name\n",
    "optimizer_name = optimizerL[round(optimum['optimizer'])]\n",
    "\n",
    "# Print the optimum parameters in a readable format\n",
    "print(f\"Best Parameters: \")\n",
    "print(f\"Activation: {activation}\")\n",
    "print(f\"Batch Size: {optimum['batch_size']}\")\n",
    "print(f\"Dropout Rate: {optimum['dropout_rate']:.4f}\")\n",
    "print(f\"Epochs: {optimum['epochs']}\")\n",
    "print(f\"Kernel Size: {optimum['kernel']}\")\n",
    "print(f\"Layers1: {optimum['layers1']}\")\n",
    "print(f\"Layers2: {optimum['layers2']}\")\n",
    "print(f\"Learning Rate: {optimum['learning_rate']:.4f}\")\n",
    "print(f\"Neurons: {optimum['neurons']}\")\n",
    "print(f\"Normalization: {optimum['normalization']:.4f}\")\n",
    "print(f\"Optimizer: {optimizer_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c6365-35bd-4b19-be8b-c28dd125485d",
   "metadata": {},
   "source": [
    "## 5. Building the CNN Model with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a53371d8-2484-446a-b640-619f942003e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - 21ms/step - accuracy: 0.5885 - loss: 1.2831\n",
      "Epoch 2/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.6681 - loss: 0.9550\n",
      "Epoch 3/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.6949 - loss: 0.8780\n",
      "Epoch 4/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7030 - loss: 0.8393\n",
      "Epoch 5/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7036 - loss: 0.8389\n",
      "Epoch 6/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7064 - loss: 0.8160\n",
      "Epoch 7/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7133 - loss: 0.8102\n",
      "Epoch 8/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7113 - loss: 0.8226\n",
      "Epoch 9/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7232 - loss: 0.7717\n",
      "Epoch 10/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7125 - loss: 0.7979\n",
      "Epoch 11/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7334 - loss: 0.7467\n",
      "Epoch 12/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7250 - loss: 0.7836\n",
      "Epoch 13/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7333 - loss: 0.7420\n",
      "Epoch 14/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7332 - loss: 0.7499\n",
      "Epoch 15/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7334 - loss: 0.7569\n",
      "Epoch 16/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.6970 - loss: 0.8397\n",
      "Epoch 17/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7176 - loss: 0.8030\n",
      "Epoch 18/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7147 - loss: 0.8196\n",
      "Epoch 19/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7334 - loss: 0.7538\n",
      "Epoch 20/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7065 - loss: 0.8378\n",
      "Epoch 21/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7155 - loss: 0.7912\n",
      "Epoch 22/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7334 - loss: 0.7510\n",
      "Epoch 23/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7474 - loss: 0.7154\n",
      "Epoch 24/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7369 - loss: 0.7469\n",
      "Epoch 25/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7453 - loss: 0.7120\n",
      "Epoch 26/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7417 - loss: 0.7202\n",
      "Epoch 27/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7539 - loss: 0.6968\n",
      "Epoch 28/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7413 - loss: 0.7286\n",
      "Epoch 29/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7502 - loss: 0.7019\n",
      "Epoch 30/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7524 - loss: 0.6982\n",
      "Epoch 31/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7219 - loss: 0.7839\n",
      "Epoch 32/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7254 - loss: 0.7588\n",
      "Epoch 33/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7237 - loss: 0.7835\n",
      "Epoch 34/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7352 - loss: 0.7351\n",
      "Epoch 35/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7405 - loss: 0.7162\n",
      "Epoch 36/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7381 - loss: 0.7350\n",
      "Epoch 37/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7337 - loss: 0.7402\n",
      "Epoch 38/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7278 - loss: 0.7581\n",
      "Epoch 39/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7419 - loss: 0.7101\n",
      "Epoch 40/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.7373 - loss: 0.7256\n",
      "Epoch 41/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7520 - loss: 0.6868\n",
      "Epoch 42/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7388 - loss: 0.7189\n",
      "Epoch 43/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7286 - loss: 0.7485\n",
      "Epoch 44/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7207 - loss: 0.7683\n",
      "Epoch 45/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7431 - loss: 0.7235\n",
      "Epoch 46/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7319 - loss: 0.7515\n",
      "Epoch 47/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7345 - loss: 0.7339\n",
      "Epoch 48/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7420 - loss: 0.7127\n",
      "Epoch 49/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7513 - loss: 0.6924\n",
      "Epoch 50/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7472 - loss: 0.7040\n",
      "Epoch 51/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7329 - loss: 0.7409\n",
      "Epoch 52/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7569 - loss: 0.6815\n",
      "Epoch 53/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7565 - loss: 0.6705\n",
      "Epoch 54/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7442 - loss: 0.6917\n",
      "Epoch 55/60\n",
      "21/21 - 0s - 4ms/step - accuracy: 0.7497 - loss: 0.6837\n",
      "Epoch 56/60\n",
      "21/21 - 0s - 4ms/step - accuracy: 0.7555 - loss: 0.6777\n",
      "Epoch 57/60\n",
      "21/21 - 0s - 4ms/step - accuracy: 0.7470 - loss: 0.6779\n",
      "Epoch 58/60\n",
      "21/21 - 0s - 4ms/step - accuracy: 0.7516 - loss: 0.6939\n",
      "Epoch 59/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7444 - loss: 0.6887\n",
      "Epoch 60/60\n",
      "21/21 - 0s - 3ms/step - accuracy: 0.7542 - loss: 0.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x37665c260>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters from optimization\n",
    "best_params = {\n",
    "    'neurons': 13,\n",
    "    'kernel': 3,\n",
    "    'activation': 'softsign',\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.0615,\n",
    "    'batch_size': 858,\n",
    "    'epochs':60,\n",
    "    'layers1': 2,\n",
    "    'layers2': 2,\n",
    "    'normalization': 0.4579,\n",
    "    'dropout': 0.40228837505867143,\n",
    "    'dropout_rate':  0.3935\n",
    "}\n",
    "\n",
    "# Initialize optimizer with learning rate\n",
    "optimizers = {\n",
    "    'Adam': Adam(learning_rate=best_params['learning_rate']),\n",
    "    'SGD': SGD(learning_rate=best_params['learning_rate']),\n",
    "    'RMSprop': RMSprop(learning_rate=best_params['learning_rate']),\n",
    "    'Adadelta': Adadelta(learning_rate=best_params['learning_rate']),\n",
    "    'Adagrad': Adagrad(learning_rate=best_params['learning_rate']),\n",
    "    'Adamax': Adamax(learning_rate=best_params['learning_rate']),\n",
    "    'Nadam': Nadam(learning_rate=best_params['learning_rate']),\n",
    "    'Ftrl': Ftrl(learning_rate=best_params['learning_rate'])\n",
    "}\n",
    "\n",
    "optimizer = optimizers[best_params['optimizer']]\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "#n_classes = len(y_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(best_params['neurons'], kernel_size=best_params['kernel'], activation=best_params['activation'], input_shape=(15,9)))\n",
    "\n",
    "if best_params['normalization'] > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for _ in range(best_params['layers1']):\n",
    "    model.add(Dense(best_params['neurons'], activation=best_params['activation']))\n",
    "\n",
    "if best_params['dropout'] > 0.5:\n",
    "    model.add(Dropout(best_params['dropout_rate'], seed=123))\n",
    "\n",
    "for _ in range(best_params['layers2']):\n",
    "    model.add(Dense(best_params['neurons'], activation=best_params['activation']))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) # sigmoid, tanh, softmax\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b2a16fc-1f31-4c38-8752-be2995819e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_95\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_95\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">364</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_480 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_481 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_482 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_483 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_484 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_95 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m364\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_480 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_481 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_482 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_483 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_95 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_95 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_484 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m1,185\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,833</span> (26.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,833\u001b[0m (26.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,277</span> (8.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,277\u001b[0m (8.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> (17.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,556\u001b[0m (17.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62611c7e-da64-479f-ae3b-bec85b07c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7493bd6-f41f-4a82-9034-8587305a11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your input data and labels\n",
    "# One-hot encode y_train\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e1a481-d0a7-4f2e-b8a7-c93784ca2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8ea3062-c27d-4389-b883-98e1f87439bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/97\n",
      "24/24 - 0s - 19ms/step - accuracy: 0.7653 - loss: 0.6648\n",
      "Epoch 2/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7723 - loss: 0.6333\n",
      "Epoch 3/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7727 - loss: 0.6277\n",
      "Epoch 4/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7728 - loss: 0.6238\n",
      "Epoch 5/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7725 - loss: 0.6210\n",
      "Epoch 6/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7732 - loss: 0.6184\n",
      "Epoch 7/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7734 - loss: 0.6168\n",
      "Epoch 8/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7754 - loss: 0.6146\n",
      "Epoch 9/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7760 - loss: 0.6137\n",
      "Epoch 10/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7752 - loss: 0.6121\n",
      "Epoch 11/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7758 - loss: 0.6119\n",
      "Epoch 12/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7759 - loss: 0.6093\n",
      "Epoch 13/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7768 - loss: 0.6084\n",
      "Epoch 14/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7779 - loss: 0.6066\n",
      "Epoch 15/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7779 - loss: 0.6056\n",
      "Epoch 16/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7762 - loss: 0.6047\n",
      "Epoch 17/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7777 - loss: 0.6036\n",
      "Epoch 18/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7768 - loss: 0.6025\n",
      "Epoch 19/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7781 - loss: 0.6015\n",
      "Epoch 20/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7786 - loss: 0.6003\n",
      "Epoch 21/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7786 - loss: 0.5996\n",
      "Epoch 22/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7777 - loss: 0.5989\n",
      "Epoch 23/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7792 - loss: 0.5979\n",
      "Epoch 24/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7811 - loss: 0.5967\n",
      "Epoch 25/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7803 - loss: 0.5958\n",
      "Epoch 26/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7803 - loss: 0.5949\n",
      "Epoch 27/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7814 - loss: 0.5938\n",
      "Epoch 28/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7807 - loss: 0.5930\n",
      "Epoch 29/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7813 - loss: 0.5930\n",
      "Epoch 30/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7831 - loss: 0.5914\n",
      "Epoch 31/97\n",
      "24/24 - 0s - 5ms/step - accuracy: 0.7821 - loss: 0.5908\n",
      "Epoch 32/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7827 - loss: 0.5904\n",
      "Epoch 33/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7824 - loss: 0.5896\n",
      "Epoch 34/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7829 - loss: 0.5886\n",
      "Epoch 35/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7841 - loss: 0.5881\n",
      "Epoch 36/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7849 - loss: 0.5888\n",
      "Epoch 37/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7833 - loss: 0.5872\n",
      "Epoch 38/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7849 - loss: 0.5868\n",
      "Epoch 39/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7850 - loss: 0.5852\n",
      "Epoch 40/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7839 - loss: 0.5849\n",
      "Epoch 41/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7853 - loss: 0.5842\n",
      "Epoch 42/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7850 - loss: 0.5837\n",
      "Epoch 43/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7858 - loss: 0.5825\n",
      "Epoch 44/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7872 - loss: 0.5817\n",
      "Epoch 45/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7858 - loss: 0.5814\n",
      "Epoch 46/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7865 - loss: 0.5806\n",
      "Epoch 47/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7871 - loss: 0.5805\n",
      "Epoch 48/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7864 - loss: 0.5789\n",
      "Epoch 49/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7867 - loss: 0.5791\n",
      "Epoch 50/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7885 - loss: 0.5783\n",
      "Epoch 51/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7879 - loss: 0.5782\n",
      "Epoch 52/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7882 - loss: 0.5769\n",
      "Epoch 53/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7879 - loss: 0.5769\n",
      "Epoch 54/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7892 - loss: 0.5757\n",
      "Epoch 55/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7888 - loss: 0.5753\n",
      "Epoch 56/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7889 - loss: 0.5750\n",
      "Epoch 57/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7885 - loss: 0.5743\n",
      "Epoch 58/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7903 - loss: 0.5739\n",
      "Epoch 59/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7878 - loss: 0.5731\n",
      "Epoch 60/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7897 - loss: 0.5724\n",
      "Epoch 61/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7903 - loss: 0.5719\n",
      "Epoch 62/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7883 - loss: 0.5716\n",
      "Epoch 63/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7892 - loss: 0.5712\n",
      "Epoch 64/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7899 - loss: 0.5710\n",
      "Epoch 65/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7904 - loss: 0.5704\n",
      "Epoch 66/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7894 - loss: 0.5700\n",
      "Epoch 67/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7902 - loss: 0.5697\n",
      "Epoch 68/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7917 - loss: 0.5686\n",
      "Epoch 69/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7919 - loss: 0.5682\n",
      "Epoch 70/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7919 - loss: 0.5676\n",
      "Epoch 71/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7906 - loss: 0.5680\n",
      "Epoch 72/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7904 - loss: 0.5688\n",
      "Epoch 73/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7910 - loss: 0.5673\n",
      "Epoch 74/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7923 - loss: 0.5661\n",
      "Epoch 75/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7905 - loss: 0.5657\n",
      "Epoch 76/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7910 - loss: 0.5658\n",
      "Epoch 77/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7919 - loss: 0.5652\n",
      "Epoch 78/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7924 - loss: 0.5642\n",
      "Epoch 79/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7928 - loss: 0.5642\n",
      "Epoch 80/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7925 - loss: 0.5635\n",
      "Epoch 81/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7921 - loss: 0.5627\n",
      "Epoch 82/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7924 - loss: 0.5627\n",
      "Epoch 83/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7922 - loss: 0.5624\n",
      "Epoch 84/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7935 - loss: 0.5627\n",
      "Epoch 85/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7922 - loss: 0.5611\n",
      "Epoch 86/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7928 - loss: 0.5609\n",
      "Epoch 87/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7926 - loss: 0.5604\n",
      "Epoch 88/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7925 - loss: 0.5615\n",
      "Epoch 89/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7922 - loss: 0.5600\n",
      "Epoch 90/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7935 - loss: 0.5598\n",
      "Epoch 91/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7929 - loss: 0.5585\n",
      "Epoch 92/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7936 - loss: 0.5587\n",
      "Epoch 93/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7924 - loss: 0.5588\n",
      "Epoch 94/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7928 - loss: 0.5586\n",
      "Epoch 95/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7935 - loss: 0.5576\n",
      "Epoch 96/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7926 - loss: 0.5583\n",
      "Epoch 97/97\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.7935 - loss: 0.5564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x384781b50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_one_hot, batch_size=744, epochs=97, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f43739d2-6ee3-491d-8bb4-ad6fafb0ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to Weather true/false\n",
    "stations = {\n",
    "0: 'BASEL',\n",
    "1: 'BELGRADE',\n",
    "2: 'BUDAPEST',\n",
    "3: 'DEBILT',\n",
    "4: 'DUSSELDORF',\n",
    "5: 'HEATHROW',\n",
    "6: 'KASSEL',\n",
    "7: 'LJUBLJANA',\n",
    "8: 'MAASTRICHT',\n",
    "9: 'MADRID',\n",
    "10: 'MUNCHENB',\n",
    "11: 'OSLO',\n",
    "12: 'SONNBLICK',\n",
    "13: 'STOCKHOLM',\n",
    "14: 'VALENTIA'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7617ca8-920e-457d-9b7d-2637b73f4847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_test: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique classes in y_test:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1f6ce75-f6e0-4302-a364-6cecd5330f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "437cf4fe-8fb4-49a2-aa8b-556b352217a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before making predictions, convert y_test to one-hot format\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ef72a64-8a28-4b8e-a57a-cb84dbecf1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step\n",
      "Accuracy: 78.11%\n"
     ]
    }
   ],
   "source": [
    "# Predict the class probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert y_test and y_pred to class labels\n",
    "if y_test_one_hot.ndim == 1:\n",
    "    y_test_labels = y_test_one_hot\n",
    "else:\n",
    "    y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "if y_pred.ndim == 1:\n",
    "    y_pred_labels = y_pred\n",
    "else:\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Manually calculate accuracy\n",
    "correct_predictions = np.sum(y_test_labels == y_pred_labels)\n",
    "total_samples = len(y_test_labels)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd9d641a-e4e8-40dd-88f9-99252924fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41986b21-0319-451b-b5b7-16f382d5ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test_one_hot back to class labels\n",
    "y_test_labels = np.argmax(y_test_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b27b1-ac89-4c5e-9eab-eb0cf2115ffd",
   "metadata": {},
   "source": [
    "## **6. Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bf7e082-72eb-42a2-bbdf-d0b22411c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  \\\n",
      "True                                                                  \n",
      "BASEL        3401       186        12       1           2        10   \n",
      "BELGRADE      351       709        14       4           0         3   \n",
      "BUDAPEST       72        72        56       3           1         5   \n",
      "DEBILT         31        18         7      18           0         6   \n",
      "DUSSELDORF     14         8         0       5           4         2   \n",
      "HEATHROW       22        16         5       5           0        34   \n",
      "KASSEL          3        10         1       0           0         0   \n",
      "LJUBLJANA      23         9         3       0           2         1   \n",
      "MAASTRICHT      4         1         0       0           0         0   \n",
      "MADRID         62        47        14       2           0        15   \n",
      "MUNCHENB       10         5         1       0           1         0   \n",
      "OSLO            3         2         0       0           0         0   \n",
      "STOCKHOLM       0         2         0       0           0         0   \n",
      "VALENTIA        1         0         1       0           0         0   \n",
      "\n",
      "Pred        LJUBLJANA  MADRID  \n",
      "True                           \n",
      "BASEL               4      84  \n",
      "BELGRADE            0      19  \n",
      "BUDAPEST            2      14  \n",
      "DEBILT              0       0  \n",
      "DUSSELDORF          0       1  \n",
      "HEATHROW            1       7  \n",
      "KASSEL              1       0  \n",
      "LJUBLJANA           5      17  \n",
      "MAASTRICHT          0       0  \n",
      "MADRID              4     255  \n",
      "MUNCHENB            0       0  \n",
      "OSLO                0       2  \n",
      "STOCKHOLM           1       1  \n",
      "VALENTIA            0       0  \n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, stations)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52d0fa29-01c1-4dba-bdb6-cf81e524aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "Unique values in y_pred: [0 1 2 3 4 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_test:\", np.unique(y_test_labels))\n",
    "print(\"Unique values in y_pred:\", np.unique(y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98203d-845d-4080-957f-2bb2c371324b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
